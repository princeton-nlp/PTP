# Improving Language Understanding from Screenshots

This repository contains the code, data, and models for paper "Improving Language Understanding from Screenshots". In this paper, we focus on improving the language understanding ability of "screenshot LM" (models that process everything -- including text -- within visual inputs) and propose patch-and-text prediction (PTP), a novel pre-training objective for screenshot LMs. 

We are still working hard to clean up the code for the release. Please stay tuned and the code/model should be ready within a week!
